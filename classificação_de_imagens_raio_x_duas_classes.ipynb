{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a11c24a"
      },
      "source": [
        "# **Classificação de imagens raio-x utilizando Deep Learning**\n",
        "\n",
        "Autor(a): Maria Eduarda Ornelas Hisse\n",
        "\n",
        "Orientador(a): Prof(a). Dra. Sílvia Cristina Dias Pinto\n",
        "\n",
        "Descrição: Algoritmo desenvolvido durante o Trabalho de Conclusão de Curso apresentado como pré-requisito para obtenção do título de Engenheiro de Computação, ao Departamento de Modelagem Computacional, do Instituto Politécnico, da Universidade do Estado do Rio de Janeiro.\n",
        "\n",
        "Objetivo: Realizar os experimentos e a obtenção dos resultados para a classificação de imagens de radiografias de tórax utilizando o conjunto de dados com uma abordagem de duas classes (e posteriormente a classe Doente será classificada em três outras classes) será  e redes neurais convolucionais."
      ],
      "id": "8a11c24a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38abf994"
      },
      "source": [
        "### *Importando as bibliotecas necessárias*"
      ],
      "id": "38abf994"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcuYcHK7puv0"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets"
      ],
      "id": "WcuYcHK7puv0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p41NU1YO-fdH"
      },
      "outputs": [],
      "source": [
        "!pip install iteration_utilities"
      ],
      "id": "p41NU1YO-fdH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e389949c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import opendatasets as op\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from iteration_utilities import duplicates\n",
        "from sklearn.model_selection import cross_validate\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report"
      ],
      "id": "e389949c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95be39e5"
      },
      "source": [
        "### *Baixando a base de dados*"
      ],
      "id": "95be39e5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfKJVHTXpz8C"
      },
      "outputs": [],
      "source": [
        "op.download(\"https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database/\")"
      ],
      "id": "WfKJVHTXpz8C"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha_VEzmINw-f"
      },
      "source": [
        "## **Lendo a base de dados**"
      ],
      "id": "ha_VEzmINw-f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b94084b"
      },
      "outputs": [],
      "source": [
        "class config:\n",
        "    seed = 42\n",
        "    img_size = [256,256]\n",
        "    msk_mode = 'grayscale'\n",
        "    img_mode = 'grayscale'\n",
        "    msk_channels = 1\n",
        "    img_channels = 1\n",
        "    img_type_num = 0\n",
        "    msk_type_num = 0\n",
        "    backbone = None\n",
        "    activation = None\n",
        "    batch_size = 16\n",
        "    train_epochs = 10\n",
        "    lr = 1e-4"
      ],
      "id": "0b94084b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9E1jsgpXBzB"
      },
      "outputs": [],
      "source": [
        "path_df = pd.DataFrame(columns=['img_path','msk_path','img_shape','msk_shape','class','subclass'])\n",
        "for cat in ['COVID','Lung_Opacity','Normal','Viral Pneumonia']:\n",
        "    dir_ = f\"covid19-radiography-database/COVID-19_Radiography_Dataset/{cat}\"\n",
        "    for f in os.listdir(f\"{dir_}/images\"):\n",
        "        s1 = cv2.imread(f\"{dir_}/images/{f}\",config.img_type_num).shape\n",
        "        s2 = cv2.imread(f\"{dir_}/masks/{f}\",config.msk_type_num).shape\n",
        "        subcat = cat\n",
        "        if cat == 'Lung_Opacity' or cat == 'COVID' or cat =='Viral Pneumonia': cat = 'Doente'\n",
        "        dic = {'img_path':f\"{dir_}/images/{f}\",'msk_path':f\"{dir_}/masks/{f}\",'img_shape':s1,'msk_shape':s2,'class': cat,'subclass': subcat}\n",
        "        path_df = path_df.append(dic,ignore_index=True)"
      ],
      "id": "w9E1jsgpXBzB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ba1ukdqTW61v"
      },
      "outputs": [],
      "source": [
        "path_df"
      ],
      "id": "Ba1ukdqTW61v"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46672b6b"
      },
      "source": [
        "### *Visualizando as imagens raio-x de cada classe*\n",
        "\n",
        "O conjunto de dados é composto por imagens de raio-x que estão classificadas em quatro classes: Covid-19, Normal, Pneumonia Viral e Lung_Opacity (Infecção Pulmonar não classificada como Covid-19)."
      ],
      "id": "46672b6b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7700f5ed"
      },
      "outputs": [],
      "source": [
        "labels = ['COVID','Lung_Opacity','Normal','Viral Pneumonia']\n",
        "for i in range(4):\n",
        "    fig, axs = plt.subplots(1,5, figsize = (50,10))\n",
        "    print('Imagens raio-x da classe', labels[i])\n",
        "    paths = [k for k in path_df['img_path'] if(labels[i] in k)]\n",
        "    for j in range(5):\n",
        "        img = cv2.imread(paths[j])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        axs[j].imshow(img)\n",
        "    plt.show()"
      ],
      "id": "7700f5ed"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6nmijqMuXnL"
      },
      "source": [
        "## **Pré-processamento da base de dados**\n",
        "\n",
        "Originalmente, as imagens são fornecidas em .png com dimensões 299 x 299, passaram pelo corte das áreas superiores e inferiores obtendo as dimensões 256 x 256."
      ],
      "id": "e6nmijqMuXnL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wwv5-IfXujgW"
      },
      "outputs": [],
      "source": [
        "def processing(image, mask):\n",
        "\n",
        "  # Lê a imagem e converte para RBG\n",
        "  image = cv2.imread(image)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "\n",
        "  # Redimensionando a imagem para a dimensão da máscara 256 x 256\n",
        "  image_res = cv2.resize(image, (256, 256))\n",
        "  plt.imshow(image_res)\n",
        "  plt.show()\n",
        "\n",
        "  # Lê a máscara correspondente a imagem e converte para RGB\n",
        "  mask = cv2.imread(mask)\n",
        "  mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "  plt.imshow(mask)\n",
        "  plt.show()\n",
        "\n",
        "  # Multiplicando a máscara e a imagem\n",
        "  mask_mult = mask // 255\n",
        "  mask_mult = image_res * mask_mult\n",
        "  plt.imshow(mask_mult)\n",
        "  plt.show()\n",
        "\n",
        "  # Invertendo a máscara\n",
        "  mask_inv = mask.copy()\n",
        "  for index, i in np.ndenumerate(mask):\n",
        "    if i == 0: mask_inv[index] = 255\n",
        "    else: mask_inv[index] = 0\n",
        "  plt.imshow(mask_inv)\n",
        "  plt.show()\n",
        "\n",
        "  # Multiplicando a máscara invertida e a imagem\n",
        "  mask_inv_mult = mask_inv // 255\n",
        "  mask_inv_mult = image_res * mask_inv_mult\n",
        "  plt.imshow(mask_inv_mult)\n",
        "  plt.show()"
      ],
      "id": "Wwv5-IfXujgW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENZFewB7v9Op"
      },
      "outputs": [],
      "source": [
        "# Lendo uma imagem da base de dados\n",
        "image = path_df['img_path'][0]\n",
        "\n",
        "# Lendo a máscara correspondente a imagem\n",
        "mask = path_df['msk_path'][0]\n",
        "\n",
        "processing(image, mask)"
      ],
      "id": "ENZFewB7v9Op"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI-ozNQw86aa"
      },
      "source": [
        "### *Pré-processamento*\n",
        "\n",
        "*   Redimensionar a imagem para 256 x 256 pixels\n",
        "*   Multiplicar a imagem e máscara\n",
        "\n"
      ],
      "id": "EI-ozNQw86aa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J3SIZmI78zr"
      },
      "outputs": [],
      "source": [
        "def pre_processing(img, mask):\n",
        "  # Redimensionando a imagem\n",
        "  img = tf.image.resize(img, (256, 256))\n",
        "\n",
        "  # Multiplicando a máscara e a imagem\n",
        "  mask = mask / 255.0\n",
        "  mask_mult = img * mask\n",
        "\n",
        "  return img, mask_mult"
      ],
      "id": "4J3SIZmI78zr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QddTcAR2nbk"
      },
      "outputs": [],
      "source": [
        "image = path_df['img_path'][0]\n",
        "mask = path_df['msk_path'][0]\n",
        "\n",
        "img = keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(image))\n",
        "mask = keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(mask))\n",
        "img, mask = pre_processing(img, mask)\n",
        "\n",
        "mask = np.asarray(mask)\n",
        "mask = mask.astype(np.uint8)\n",
        "plt.imshow(mask[:,:,0], cmap=\"gray\")\n",
        "plt.show()"
      ],
      "id": "4QddTcAR2nbk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54c57027"
      },
      "source": [
        "## **Balanceamento da base de dados**\n",
        "\n",
        "Rebalanceamento dos dados para garantir que cada lote seja balanceado em termos de classes (cross-validation, treinamento, teste e validação).\n",
        "\n",
        "Técnica *Under-Sampling* reduz o desbalanceamento do dataset focando na classe majoritária. Ou seja, elimina aleatoriamente entradas da classe com maior número de ocorrências."
      ],
      "id": "54c57027"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEo79Wh_SK0B"
      },
      "source": [
        "### *Distribuição da base de dados antes do balanceamento*"
      ],
      "id": "WEo79Wh_SK0B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NZMt_JnSJO-"
      },
      "outputs": [],
      "source": [
        "images = np.asarray(path_df['img_path'])\n",
        "classes = np.asarray(path_df['class'])\n",
        "\n",
        "# Ver o balanceamento das classes\n",
        "print(pd.Series(classes).value_counts())\n",
        "\n",
        "# Plotar a nova distribuição de classes\n",
        "sns.countplot(x=classes)"
      ],
      "id": "8NZMt_JnSJO-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP89ZY9QSmhi"
      },
      "source": [
        "### *Distribuição da base de dados após o balanceamento*"
      ],
      "id": "wP89ZY9QSmhi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBeFmkcb2R7A"
      },
      "outputs": [],
      "source": [
        "# Balanceando a base de dados para a classificação das classes através da técnica under-slamping\n",
        "def balanced_under_sampler():\n",
        "  rus = RandomUnderSampler(replacement = False)\n",
        "  x_res, y_res = rus.fit_resample(images.reshape(-1, 1), classes.reshape(-1, 1))\n",
        "\n",
        "  x_res = x_res.reshape(-1)\n",
        "  return x_res, y_res"
      ],
      "id": "kBeFmkcb2R7A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2VE8gS2vgG7"
      },
      "outputs": [],
      "source": [
        "# Balanceando a base de dados para a classificação das classes escolhendo aleatoriamente as imagens utilizadas\n",
        "def balanced_random():\n",
        "  x_res = []\n",
        "  y_res = []\n",
        "\n",
        "  for cat in ['COVID','Lung_Opacity','Normal','Viral Pneumonia']:\n",
        "    dir_ = f\"covid19-radiography-database/COVID-19_Radiography_Dataset/{cat}\"\n",
        "    path = os.listdir(f\"{dir_}/images/\")\n",
        "    list_numbers = random.sample(range(len(path)), pd.Series(classes).value_counts().min())\n",
        "    for i in list_numbers:\n",
        "        x_res.append(f\"{dir_}/images/{path[i]}\")\n",
        "        y_res.append(cat)\n",
        "  return x_res, y_res"
      ],
      "id": "w2VE8gS2vgG7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skJS8D8oPKQC"
      },
      "source": [
        "## **Dividindo a base de dados em treinamento, teste e validação**\n",
        "\n",
        "A base de dados foi dividida em três conjuntos de treinamento, teste e validação. Sendo 70% da base destinada a treinamento do modelo de classificação, 10% a validação e 20% a teste."
      ],
      "id": "skJS8D8oPKQC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61791569"
      },
      "outputs": [],
      "source": [
        "def divide_base_date(x_res, segmentacao):\n",
        "  # Embaralhando a base de dados\n",
        "  random.shuffle(x_res)\n",
        "\n",
        "  # Conjunto de treinamento\n",
        "  X_train = []\n",
        "  y_train = []\n",
        "  y_train_doente = []\n",
        "  x_res = x_res[1:10000]\n",
        "  for train in x_res[0:int(len(x_res)*0.7)]:\n",
        "    img = keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(train))\n",
        "    img, mask = pre_processing(img, mask)\n",
        "    mask = keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(train.replace(\"images\", \"masks\")))\n",
        "    if segmentacao:\n",
        "      X_train.append(np.array(mask, dtype=np.float16))\n",
        "    else:\n",
        "      X_train.append(np.array(img, dtype=np.float16))\n",
        "    classe = train.split('/')[-3]\n",
        "    y_train_doente.append(classe)\n",
        "    if classe == 'Lung_Opacity' or classe == 'COVID' or classe =='Viral Pneumonia': classe = 'Doente'\n",
        "    y_train.append(classe)\n",
        "\n",
        "  # Conjunto de validação\n",
        "  X_val = []\n",
        "  y_val = []\n",
        "  y_val_doente = []\n",
        "  for val in x_res[int(len(x_res)*0.7):int(len(x_res)*0.8)]:\n",
        "    img = keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(val))\n",
        "    mask = keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(val.replace(\"images\", \"masks\")))\n",
        "    img, mask = pre_processing(img, mask)\n",
        "    if segmentacao:\n",
        "      X_val.append(np.array(mask, dtype=np.float16))\n",
        "    else:\n",
        "      X_val.append(np.array(img, dtype=np.float16))\n",
        "    classe = val.split('/')[-3]\n",
        "    y_val_doente.append(classe)\n",
        "    if classe == 'Lung_Opacity' or classe == 'COVID' or classe =='Viral Pneumonia': classe = 'Doente'\n",
        "    y_val.append(classe)\n",
        "\n",
        "  # Conjunto de teste\n",
        "  X_test = []\n",
        "  y_test = []\n",
        "  y_test_doente = []\n",
        "  for test in x_res[int(len(x_res)*0.8):int(len(x_res))]:\n",
        "    img = keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(test))\n",
        "    mask = keras.preprocessing.image.img_to_array(keras.preprocessing.image.load_img(test.replace(\"images\", \"masks\")))\n",
        "    img, mask = pre_processing(img, mask)\n",
        "    if segmentacao:\n",
        "      X_test_mask.append(np.array(mask, dtype=np.float16))\n",
        "    else:\n",
        "      X_test.append(np.array(img, dtype=np.float16))\n",
        "    classe = test.split('/')[-3]\n",
        "    y_test_doente.append(classe)\n",
        "    if classe == 'Lung_Opacity' or classe == 'COVID' or classe =='Viral Pneumonia': classe = 'Doente'\n",
        "    y_test.append(classe)\n",
        "\n",
        "  return X_train, X_val, X_test, X_train_mask, X_val_mask, X_test_mask, y_train, y_val, y_test, y_train_doente, y_val_doente, y_test_doente"
      ],
      "id": "61791569"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5ALIAip0_jp"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, X_test, X_train_mask, X_val_mask, X_test_mask, y_train, y_val, y_test, y_train_doente, y_val_doente, y_test_doente = divide_base_date(images, 0)"
      ],
      "id": "Q5ALIAip0_jp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2c4b2ab"
      },
      "source": [
        "### Número de imagens de cada conjunto"
      ],
      "id": "e2c4b2ab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07407f36"
      },
      "outputs": [],
      "source": [
        "print('Quantidade de imagens do conjunto de treinamento:', len(y_train))\n",
        "print('Quantidade de imagens do conjunto de validação:', len(y_val))\n",
        "print('Quantidade de imagens do conjunto de teste:', len(y_test))"
      ],
      "id": "07407f36"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJgu2kU85nfl"
      },
      "source": [
        "### *Etiquetas de codificação*"
      ],
      "id": "QJgu2kU85nfl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z51YUvzGtb9",
        "outputId": "9649838b-e9b7-4a93-9589-777196cd2dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Doente', 'Normal']\n"
          ]
        }
      ],
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train_enconder = encoder.fit_transform(y_train)\n",
        "y_val_enconder = encoder.fit_transform(y_val)\n",
        "y_test_enconder = encoder.fit_transform(y_test)\n",
        "\n",
        "classes = list(encoder.classes_)\n",
        "print(classes)"
      ],
      "id": "5z51YUvzGtb9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSluInDGILad"
      },
      "source": [
        "### *Transformando o conjunto de dados em um array*"
      ],
      "id": "sSluInDGILad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSQdwnS95hcM"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(X_train)\n",
        "X_val = np.array(X_val)\n",
        "X_test = np.array(X_test)"
      ],
      "id": "XSQdwnS95hcM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCSPcHpUH6q9"
      },
      "outputs": [],
      "source": [
        "X_train_mask = np.array(X_train_mask)\n",
        "X_val_mask = np.array(X_val_mask)\n",
        "X_test_mask = np.array(X_test_mask)"
      ],
      "id": "pCSPcHpUH6q9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FkOPuzZ0mk_"
      },
      "source": [
        "## **ResNet-50**"
      ],
      "id": "_FkOPuzZ0mk_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNPVepNJ4ko-"
      },
      "outputs": [],
      "source": [
        "def ResNet50(len_inputs, len_classes):\n",
        "  baseModel = keras.applications.ResNet50V2(weights = 'imagenet', include_top = False, input_shape = len_inputs)\n",
        "\n",
        "  for layer in baseModel.layers: layer.trainable=False\n",
        "\n",
        "  headModel = baseModel.output\n",
        "  headModel = keras.layers.Dropout(0.5)(headModel)\n",
        "  headModel = keras.layers.Flatten()(headModel)\n",
        "  headModel = keras.layers.BatchNormalization()(headModel)\n",
        "\n",
        "  headModel = keras.layers.Dense(2048, activation = \"relu\")(headModel)\n",
        "  headModel = keras.layers.BatchNormalization()(headModel)\n",
        "  headModel = keras.layers.Dropout(0.5)(headModel)\n",
        "  headModel = keras.layers.Dense(1024, activation = \"relu\")(headModel)\n",
        "  headModel = keras.layers.BatchNormalization()(headModel)\n",
        "  headModel = keras.layers.Dropout(0.5)(headModel)\n",
        "\n",
        "  headModel = keras.layers.Dense(len_classes, activation = \"softmax\")(headModel)\n",
        "  model = keras.models.Model(inputs = baseModel.input, outputs = headModel)\n",
        "\n",
        "  return model"
      ],
      "id": "YNPVepNJ4ko-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGqwK_B_0qWt"
      },
      "source": [
        "## **ResNet-101**"
      ],
      "id": "DGqwK_B_0qWt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSflcPsi2isi"
      },
      "outputs": [],
      "source": [
        "def ResNet101(len_inputs, len_classes):\n",
        "  baseModel = keras.applications.ResNet101V2(weights = 'imagenet', include_top = False, input_shape = len_inputs)\n",
        "\n",
        "  for layer in baseModel.layers: layer.trainable = False\n",
        "\n",
        "  headModel = baseModel.output\n",
        "  headModel = keras.layers.Dropout(0.5)(headModel)\n",
        "  headModel = keras.layers.Flatten()(headModel)\n",
        "  headModel = keras.layers.BatchNormalization()(headModel)\n",
        "\n",
        "  headModel = keras.layers.Dense(2048, activation = \"relu\")(headModel)\n",
        "  headModel = keras.layers.BatchNormalization()(headModel)\n",
        "  headModel = keras.layers.Dropout(0.5)(headModel)\n",
        "  headModel = keras.layers.Dense(1024, activation = \"relu\")(headModel)\n",
        "  headModel = keras.layers.BatchNormalization()(headModel)\n",
        "  headModel = keras.layers.Dropout(0.5)(headModel)\n",
        "\n",
        "  headModel = keras.layers.Dense(len_classes, activation = \"softmax\")(headModel)\n",
        "  model = keras.models.Model(inputs = baseModel.input, outputs = headModel)\n",
        "\n",
        "  return model"
      ],
      "id": "fSflcPsi2isi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKSGotpF-cfW"
      },
      "source": [
        "## **VGG-16**"
      ],
      "id": "nKSGotpF-cfW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9N74e7M-ady"
      },
      "outputs": [],
      "source": [
        "def VGG16(len_inputs, len_classes):\n",
        "    baseModel = keras.applications.VGG16(weights = 'imagenet', include_top = False, input_shape = len_inputs)\n",
        "\n",
        "    for layer in baseModel.layers: layer.trainable = False\n",
        "\n",
        "    headModel = baseModel.output\n",
        "    headModel = keras.layers.GlobalAveragePooling2D()(headModel)\n",
        "    headModel = keras.layers.BatchNormalization()(headModel)\n",
        "\n",
        "    headModel = keras.layers.Dense(128, activation=\"relu\")(headModel)\n",
        "    headModel = keras.layers.BatchNormalization()(headModel)\n",
        "    headModel = keras.layers.Dense(64, activation=\"relu\")(headModel)\n",
        "    headModel = keras.layers.BatchNormalization()(headModel)\n",
        "\n",
        "    headModel = keras.layers.Dense(len_classes, activation=\"softmax\")(headModel)\n",
        "    model = keras.models.Model(inputs = baseModel.input, outputs = headModel)\n",
        "\n",
        "    return model"
      ],
      "id": "u9N74e7M-ady"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsP6dEl30VyP"
      },
      "source": [
        "## **VGG-19**"
      ],
      "id": "XsP6dEl30VyP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TACop70e0YGl"
      },
      "outputs": [],
      "source": [
        "def VGG19(len_inputs, len_classes):\n",
        "    baseModel = keras.applications.VGG19(weights= 'imagenet', include_top = False, input_shape = len_inputs)\n",
        "\n",
        "    for layer in baseModel.layers: layer.trainable = False\n",
        "\n",
        "    headModel = baseModel.output\n",
        "    headModel = keras.layers.GlobalAveragePooling2D()(headModel)\n",
        "    headModel = keras.layers.BatchNormalization()(headModel)\n",
        "\n",
        "    headModel = keras.layers.Dense(128, activation=\"relu\")(headModel)\n",
        "    headModel = keras.layers.BatchNormalization()(headModel)\n",
        "    headModel = keras.layers.Dense(64, activation=\"relu\")(headModel)\n",
        "    headModel = keras.layers.BatchNormalization()(headModel)\n",
        "\n",
        "    headModel = keras.layers.Dense(len_classes, activation=\"softmax\")(headModel)\n",
        "    model = keras.models.Model(inputs = baseModel.input, outputs = headModel)\n",
        "\n",
        "    return model"
      ],
      "id": "TACop70e0YGl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTvpKhZr3Y9g"
      },
      "source": [
        "## **Xception**"
      ],
      "id": "ZTvpKhZr3Y9g"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NPGxzj33gTI"
      },
      "outputs": [],
      "source": [
        "def Xception(len_inputs, len_classes):\n",
        "  baseModel = keras.applications.Xception(weights = 'imagenet', include_top = False, input_shape = len_inputs)\n",
        "\n",
        "  for layer in baseModel.layers: layer.trainable = False\n",
        "\n",
        "  headModel = baseModel.output\n",
        "  headModel = keras.layers.GlobalAveragePooling2D(name = 'avg_pool')(headModel)\n",
        "  headModel = keras.layers.Dropout(0.75)(headModel)\n",
        "  headModel = keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.01, center=True, scale=True, beta_initializer=\"zeros\", gamma_initializer=\"ones\", moving_mean_initializer=\"zeros\", moving_variance_initializer=\"ones\")(headModel)\n",
        "\n",
        "  headModel = keras.layers.Dense(len_classes, activation = 'softmax')(headModel)\n",
        "  model = keras.models.Model(inputs = baseModel.input, outputs = headModel)\n",
        "\n",
        "  return model\n"
      ],
      "id": "7NPGxzj33gTI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBTakchcDCCF"
      },
      "source": [
        "## **DenseNet-121**"
      ],
      "id": "kBTakchcDCCF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jtwNKh9DBhG"
      },
      "outputs": [],
      "source": [
        "def DenseNet121(len_inputs, len_classes):\n",
        "  baseModel = keras.applications.DenseNet121(weights = 'imagenet', include_top = False, input_shape = len_inputs)\n",
        "\n",
        "  for layer in baseModel.layers: layer.trainable = False\n",
        "\n",
        "  headModel = baseModel.output\n",
        "  headModel = keras.layers.Dropout(0.3)(headModel)\n",
        "  headModel = keras.layers.Flatten()(headModel)\n",
        "  headModel = keras.layers.Dense(64, activation='tanh',kernel_initializer=keras.initializers.GlorotNormal(),bias_regularizer=tf.keras.regularizers.L2(0.0001), kernel_regularizer=tf.keras.regularizers.L2(0.0001), activity_regularizer = tf.keras.regularizers.L2(0.0001))(headModel)\n",
        "  headModel = keras.layers.Dropout(0.3)(headModel)\n",
        "  headModel = keras.layers.Dense(32, activation='tanh',kernel_initializer=keras.initializers.GlorotNormal(),bias_regularizer=tf.keras.regularizers.L2(0.0001) ,kernel_regularizer=tf.keras.regularizers.L2(0.0001), activity_regularizer = tf.keras.regularizers.L2(0.0001))(headModel)\n",
        "  headModel = keras.layers.Dropout(0.3)(headModel)\n",
        "  headModel = keras.layers.Dense(16, activation='tanh',kernel_initializer=keras.initializers.GlorotNormal(),bias_regularizer=tf.keras.regularizers.L2(0.0001) ,kernel_regularizer=tf.keras.regularizers.L2(0.0001), activity_regularizer = tf.keras.regularizers.L2(0.0001))(headModel)\n",
        "  headModel = keras.layers.Dropout(0.3)(headModel)\n",
        "\n",
        "  headModel = keras.layers.Dense(len_classes, activation='softmax', kernel_initializer=keras.initializers.GlorotNormal(), bias_regularizer=tf.keras.regularizers.L2(0.0001),kernel_regularizer=tf.keras.regularizers.L2(0.0001), activity_regularizer = tf.keras.regularizers.L2(0.0001))(headModel)\n",
        "  model = keras.models.Model(inputs = baseModel.input, outputs = headModel)\n",
        "\n",
        "  return model"
      ],
      "id": "3jtwNKh9DBhG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwpxrVR9bsYl"
      },
      "source": [
        "## **MobileNetV2**"
      ],
      "id": "BwpxrVR9bsYl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e81PThCce8oo"
      },
      "outputs": [],
      "source": [
        "def MobileNetV2(len_inputs, len_classes):\n",
        "  baseModel = keras.applications.MobileNetV2(weights = 'imagenet', include_top = False, input_shape = len_inputs)\n",
        "\n",
        "  for layer in baseModel.layers: layer.trainable = False\n",
        "\n",
        "  headModel = baseModel.output\n",
        "  headModel = keras.layers.Flatten()(headModel)\n",
        "  headModel = keras.layers.Dense(1024, activation='relu')(headModel)\n",
        "  headModel = keras.layers.BatchNormalization()(headModel)\n",
        "  headModel = keras.layers.Dense(512, activation='relu')(headModel)\n",
        "  headModel = keras.layers.BatchNormalization()(headModel)\n",
        "  headModel = keras.layers.Dense(128, activation='relu')(headModel)\n",
        "  headModel = keras.layers.Dropout(0.15)(headModel)\n",
        "  headModel = keras.layers.BatchNormalization()(headModel)\n",
        "  headModel = keras.layers.Dense(64, activation='relu')(headModel)\n",
        "  headModel = keras.layers.Dropout(0.3)(headModel)\n",
        "  headModel = keras.layers.BatchNormalization()(headModel)\n",
        "\n",
        "  headModel = keras.layers.Dense(len_classes, activation=\"softmax\")(headModel)\n",
        "  model = keras.models.Model(inputs = baseModel.input, outputs = headModel)\n",
        "\n",
        "  return model"
      ],
      "id": "e81PThCce8oo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GnddJKPbzOW"
      },
      "source": [
        "## **InceptionV3**"
      ],
      "id": "_GnddJKPbzOW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITShX5Cwh5Kh"
      },
      "outputs": [],
      "source": [
        "def InceptionV3(len_inputs, len_classes):\n",
        "  baseModel = keras.applications.InceptionV3(weights = 'imagenet', include_top = False, input_shape = len_inputs)\n",
        "\n",
        "  for layer in baseModel.layers: layer.trainable = False\n",
        "\n",
        "  headModel = baseModel.output\n",
        "  headModel = keras.layers.GlobalAveragePooling2D()(headModel)\n",
        "  headModel = keras.layers.Dense(1024, activation='relu')(headModel)\n",
        "  headModel = keras.layers.BatchNormalization()(headModel)\n",
        "  headModel = keras.layers.Dense(512, activation='relu')(headModel)\n",
        "  headModel = keras.layers.BatchNormalization()(headModel)\n",
        "  headModel = keras.layers.Dense(128, activation='relu')(headModel)\n",
        "  headModel = keras.layers.Dropout(0.15)(headModel)\n",
        "  headModel = keras.layers.BatchNormalization()(headModel)\n",
        "  headModel = keras.layers.Dense(64, activation='relu')(headModel)\n",
        "  headModel = keras.layers.Dropout(0.3)(headModel)\n",
        "  headModel = keras.layers.BatchNormalization()(headModel)\n",
        "\n",
        "  headModel = keras.layers.Dense(len_classes, activation=\"softmax\")(headModel)\n",
        "  model = keras.models.Model(inputs = baseModel.input, outputs = headModel)\n",
        "\n",
        "  return model"
      ],
      "id": "ITShX5Cwh5Kh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfS9v26b02sM"
      },
      "source": [
        "## **Escolha do modelo**"
      ],
      "id": "YfS9v26b02sM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7FISjQb-ryR"
      },
      "outputs": [],
      "source": [
        "def model_classifier(model, len_inputs, len_classes):\n",
        "  if model == \"vgg16\":\n",
        "    model = VGG16(len_inputs, len_classes)\n",
        "  elif model == \"vgg19\":\n",
        "    model = VGG19(len_inputs, len_classes)\n",
        "  elif model == \"resnet50\":\n",
        "    model = ResNet50(len_inputs, len_classes)\n",
        "  elif model == \"resnet101\":\n",
        "    model = ResNet101(len_inputs, len_classes)\n",
        "  elif model == \"xception\":\n",
        "    model = Xception(len_inputs, len_classes)\n",
        "  elif model == \"densenet121\":\n",
        "    model = DenseNet121(len_inputs, len_classes)\n",
        "  elif model == \"mobilenetv2\":\n",
        "    model = MobileNetV2(len_inputs, len_classes)\n",
        "  elif model == \"inceptionv3\":\n",
        "    model = InceptionV3(len_inputs, len_classes)\n",
        "  else:\n",
        "    model = -1\n",
        "\n",
        "  return model"
      ],
      "id": "r7FISjQb-ryR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DH4iHKT0aVCn"
      },
      "outputs": [],
      "source": [
        "classifier = \"inceptionv3\"\n",
        "len_inputs = (256, 256, 3)\n",
        "len_classes = 4\n",
        "learning_rate = 0.00001\n",
        "loss = 'sparse_categorical_crossentropy'\n",
        "optimizers = keras.optimizers.Adam(learning_rate = learning_rate)"
      ],
      "id": "DH4iHKT0aVCn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN6cG4CVaXg0"
      },
      "outputs": [],
      "source": [
        "model = model_classifier(classifier, len_inputs, len_classes)"
      ],
      "id": "SN6cG4CVaXg0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORvPlslDad1G"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = loss, optimizer = optimizers, metrics = ['accuracy'])"
      ],
      "id": "ORvPlslDad1G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydYTl2Gb2JVV"
      },
      "outputs": [],
      "source": [
        "print('Sumário do modelo:', classifier)\n",
        "model.summary()"
      ],
      "id": "ydYTl2Gb2JVV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a156e9b"
      },
      "source": [
        "## **Treinamento do modelo e salvando em cada época**"
      ],
      "id": "3a156e9b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17c06ca8"
      },
      "source": [
        "Aqui, o modelo é salvo em cada época em que val_accuracy for maior que seus valores anteriores. Então, esse modelo pode ser usado mais tarde para uma melhor generalização."
      ],
      "id": "17c06ca8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "634b4dae"
      },
      "outputs": [],
      "source": [
        "def model_fit(checkpoint_path):\n",
        "  early_stopping = keras.callbacks.EarlyStopping(monitor='loss', patience = 3)\n",
        "  reduce_lr =  keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
        "  learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=2, factor=0.5, min_lr=0.00001)\n",
        "\n",
        "  checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "  model_check = keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, monitor = 'val_accuracy', mode = 'max', save_best_only=True, verbose=1)\n",
        "\n",
        "  cp_callback = [early_stopping, reduce_lr , learning_rate_reduction, model_check]\n",
        "\n",
        "  return cp_callback"
      ],
      "id": "634b4dae"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WJtL804wO3O"
      },
      "outputs": [],
      "source": [
        "epochs = 40\n",
        "batch_size = 32"
      ],
      "id": "0WJtL804wO3O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySVTlwqF4S8Z"
      },
      "outputs": [],
      "source": [
        "model_history = model.fit(X_train, y_train_enconder, epochs = epochs, batch_size = batch_size, validation_data = (X_val, y_val_enconder))"
      ],
      "id": "ySVTlwqF4S8Z"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e1a2768"
      },
      "source": [
        "## **Gráficos de Accuracy, Val_Accuracy, Loss e Val_Loss**"
      ],
      "id": "5e1a2768"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWA-_kgDm7b8"
      },
      "outputs": [],
      "source": [
        "model_history.history"
      ],
      "id": "MWA-_kgDm7b8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4uU8Cmc2txT"
      },
      "outputs": [],
      "source": [
        "epochs = len(model_history.history['accuracy'])"
      ],
      "id": "N4uU8Cmc2txT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07480e85"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1,2, figsize = (20,7))\n",
        "axs[0].plot(np.arange(1, epochs + 1), model_history.history['accuracy'], label = 'Accuracy')\n",
        "axs[0].plot(np.arange(1, epochs + 1), model_history.history['val_accuracy'], label = 'Val Accuracy')\n",
        "axs[0].legend()\n",
        "axs[0].grid()\n",
        "\n",
        "axs[1].plot(np.arange(1, epochs + 1), model_history.history['loss'], label = 'Loss')\n",
        "axs[1].plot(np.arange(1, epochs + 1), model_history.history['val_loss'], label = 'Val Loss')\n",
        "axs[1].legend()\n",
        "axs[1].grid()\n",
        "\n",
        "plt.title(\"Modelo \" + classifier)\n",
        "plt.show()"
      ],
      "id": "07480e85"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97b28c71"
      },
      "source": [
        "## **Predições**"
      ],
      "id": "97b28c71"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c37e74b4"
      },
      "outputs": [],
      "source": [
        "prob_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(prob_pred, axis=1)"
      ],
      "id": "c37e74b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b32c6c7"
      },
      "source": [
        "### *Acurácia no Conjunto de Teste*"
      ],
      "id": "2b32c6c7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc100bef"
      },
      "outputs": [],
      "source": [
        "print('Acurácia no Conjunto de Teste:', accuracy_score(y_test_enconder, y_pred))\n",
        "print('Relatório de Classificação:')\n",
        "print(classification_report(encoder.inverse_transform(y_test_enconder), encoder.inverse_transform(y_pred), zero_division = 1))"
      ],
      "id": "dc100bef"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXIVbBdinvNr"
      },
      "source": [
        "### *Avaliação no conjunto de teste*\n",
        "\n",
        "Retorna o valor de perda e os valores de métricas para o modelo no modo de teste."
      ],
      "id": "OXIVbBdinvNr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEhUUa7enKxE"
      },
      "outputs": [],
      "source": [
        "evalute = model.evaluate(X_test, y_test_enconder)"
      ],
      "id": "XEhUUa7enKxE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naLnerPDnof-"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy: {:.2f}%\".format(evalute[1] * 100))\n",
        "print(\"Loss: {}\".format(evalute[0]))"
      ],
      "id": "naLnerPDnof-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQv16-fIY0DP"
      },
      "source": [
        "### *Matriz de Confusão*"
      ],
      "id": "nQv16-fIY0DP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_1O5-VmYyVn"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test_enconder, y_pred)"
      ],
      "id": "Q_1O5-VmYyVn"
    },
    {
      "cell_type": "code",
      "source": [
        "cm"
      ],
      "metadata": {
        "id": "baorzOuhqpnN"
      },
      "id": "baorzOuhqpnN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2HvYX4E9gRv"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(11,7))\n",
        "x_axis_labels = classes\n",
        "y_axis_labels = classes\n",
        "plt.rcParams.update({'font.size': 25})\n",
        "sns.heatmap(cm, xticklabels = x_axis_labels, yticklabels = y_axis_labels, annot= True, fmt='',cmap = 'Blues')\n",
        "plt.xlabel('Predição', fontsize = 20)\n",
        "plt.ylabel(\"Real\", fontsize = 20)\n",
        "plt.title('Matriz de confusão ')\n",
        "plt.show()"
      ],
      "id": "E2HvYX4E9gRv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdiz7rPleMby"
      },
      "source": [
        "## **Mapa de Calor (Grad-CAM)**"
      ],
      "id": "kdiz7rPleMby"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNvGtO8UfjG0"
      },
      "outputs": [],
      "source": [
        "def get_img_array(img_path, size):\n",
        "    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n",
        "    array = keras.preprocessing.image.img_to_array(img)\n",
        "    array = np.expand_dims(array, axis=0)\n",
        "    return array"
      ],
      "id": "yNvGtO8UfjG0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzNRWGAWeL_z"
      },
      "outputs": [],
      "source": [
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n",
        "\n",
        "    # Compita-se o gradiente da classe superior prevista para nossa imagem de entrada em relação às ações da última camada de conversão\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # Este é o gradiente do neurônio de saída (top previsto ou escolhido) em relação ao mapa de recursos de saída da última camada de conversão\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # Este é um vetor onde cada entrada é a intensidade média do gradiente sobre um canal específico do mapa de recursos\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Multiplica-se cada canal na matriz do mapa de recursos por \"quão importante é esse canal\" em relação à classe mais alta prevista\n",
        "    # Em seguida, somamos todos os canais para obter a ativação da classe do mapa de calor\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # Para fins de visualização, também normalizaremos o mapa de calor entre 0 e 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()"
      ],
      "id": "CzNRWGAWeL_z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kq9rDzMkfxxK"
      },
      "outputs": [],
      "source": [
        "def save_and_display_gradcam(img, heatmap, cam_path=\"cam.jpg\", alpha=0.4):\n",
        "    # Redimensiona-se o mapa de calor para um intervalo de 0 a 255\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Usa-se o mapa de cores do jato para colorir o mapa de calor\n",
        "    jet = plt.get_cmap(\"jet\")\n",
        "\n",
        "    # Use valores RGB do mapa de cores\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "    # Cria-se uma imagem com mapa de calor colorido RGB\n",
        "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "    # Sobrepõe-se o mapa de calor na imagem original\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "    # Salva-se a imagem sobreposta\n",
        "    superimposed_img.save(cam_path)\n",
        "\n",
        "    return cam_path"
      ],
      "id": "Kq9rDzMkfxxK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQ9ads0Rf4Dq"
      },
      "outputs": [],
      "source": [
        "preprocess_input = keras.applications.mobilenet_v2.preprocess_input\n",
        "decode_predictions = keras.applications.mobilenet_v2.decode_predictions\n",
        "\n",
        "last_conv_layer_name = 'conv2d_93'\n",
        "\n",
        "# Remove-se o softmax da última camada\n",
        "model.layers[-1].activation = None"
      ],
      "id": "NQ9ads0Rf4Dq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yQNCc3mfUdc"
      },
      "outputs": [],
      "source": [
        "# Exibe a parte das imagens usadas pela rede neural para classificar as imagens\n",
        "fig, axes = plt.subplots(nrows = 4, ncols = 4, figsize = (20, 20), subplot_kw = {'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    img_array = X_test[i]\n",
        "    heatmap = make_gradcam_heatmap(img_array.reshape(1, 256, 256, 3), model, last_conv_layer_name)\n",
        "    cam_path = save_and_display_gradcam(img_array, heatmap, \"cam.jpg\", 0.8)\n",
        "    class_test = classes[y_test_enconder[i]]\n",
        "    class_prediction = classes[y_pred[i]]\n",
        "    ax.imshow(plt.imread(cam_path))\n",
        "    ax.set_title(f\"True: {class_test}\\nPredicted: {class_prediction}\", fontsize = 14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "3yQNCc3mfUdc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfc92653"
      },
      "source": [
        "## **Carregando pesos de modelo do ponto de verificação e reavaliar**"
      ],
      "id": "cfc92653"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Três Classes**\n",
        "\n",
        "Classificação da classe Doente em três subclasses: Covid, Viral Pneumonia e Lung_Opacity."
      ],
      "metadata": {
        "id": "mifdD-x2JPfQ"
      },
      "id": "mifdD-x2JPfQ"
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_doente = []\n",
        "y_test_doente2 = []\n",
        "for i in range(len(y_test)):\n",
        "  if y_test[i] == 'Doente':\n",
        "    X_test_doente.append(X_test[i])\n",
        "    y_test_doente2.append(y_test_doente[i])\n",
        "\n",
        "X_val_doente = []\n",
        "y_val_doente2 = []\n",
        "for i in range(len(y_val)):\n",
        "  if y_val[i] == 'Doente':\n",
        "    X_val_doente.append(X_val[i])\n",
        "    y_val_doente2.append(y_val_doente[i])\n",
        "\n",
        "X_train_doente = []\n",
        "y_train_doente2 = []\n",
        "for i in range(len(y_train)):\n",
        "  if y_train[i] == 'Doente':\n",
        "    X_train_doente.append(X_train[i])\n",
        "    y_train_doente2.append(y_train_doente[i])"
      ],
      "metadata": {
        "id": "CKrYwZPbY1Mw"
      },
      "id": "CKrYwZPbY1Mw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Quatidade de imagens do conjunto de treinamento:', len(y_train_doente2))\n",
        "print('Quatidade de imagens do conjunto de validação:', len(y_val_doente2))\n",
        "print('Quatidade de imagens do conjunto de teste:', len(y_test_doente2))"
      ],
      "metadata": {
        "id": "p4naMLl4KQ77"
      },
      "id": "p4naMLl4KQ77",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = LabelEncoder()\n",
        "y_train_doente2 = encoder.fit_transform(y_train_doente2)\n",
        "y_val_doente2 = encoder.fit_transform(y_val_doente2)\n",
        "y_test_doente2 = encoder.fit_transform(y_test_doente2)\n",
        "\n",
        "X_train_doente = np.array(X_train_doente)\n",
        "X_val_doente = np.array(X_val_doente)\n",
        "X_test_doente = np.array(X_test_doente)\n",
        "\n",
        "classes_doente = list(encoder.classes_)\n",
        "print(classes_doente)"
      ],
      "metadata": {
        "id": "bnReQuroKTL8"
      },
      "id": "bnReQuroKTL8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = model.fit(X_train_doente, y_train_doente2, epochs = epochs, batch_size = batch_size, validation_data = (X_val_doente, y_val_doente2))"
      ],
      "metadata": {
        "id": "_qsaJnpsKWL6"
      },
      "id": "_qsaJnpsKWL6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history.history"
      ],
      "metadata": {
        "id": "ALaizv3uKYz5"
      },
      "id": "ALaizv3uKYz5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,2, figsize = (20,7))\n",
        "axs[0].plot(np.arange(1, epochs + 1), model_history.history['accuracy'], label = 'Accuracy')\n",
        "axs[0].plot(np.arange(1, epochs + 1), model_history.history['val_accuracy'], label = 'Val Accuracy')\n",
        "axs[0].legend()\n",
        "axs[0].grid()\n",
        "\n",
        "axs[1].plot(np.arange(1, epochs + 1), model_history.history['loss'], label = 'Loss')\n",
        "axs[1].plot(np.arange(1, epochs + 1), model_history.history['val_loss'], label = 'Val Loss')\n",
        "axs[1].legend()\n",
        "axs[1].grid()\n",
        "\n",
        "plt.title(\"Modelo \" + classifier)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mv5LMuZwKfOU"
      },
      "id": "Mv5LMuZwKfOU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prob_pred_doente = model.predict(X_test_doente)\n",
        "y_pred_doente = np.argmax(prob_pred_doente, axis=1)"
      ],
      "metadata": {
        "id": "hL1FKfS0Kf6r"
      },
      "id": "hL1FKfS0Kf6r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Acurácia no Conjunto de Teste:', accuracy_score(y_test_doente2, y_pred_doente))\n",
        "print('Relatório de Classificação:')\n",
        "print(classification_report(encoder.inverse_transform(y_test_doente2), encoder.inverse_transform(y_pred_doente), zero_division = 1))"
      ],
      "metadata": {
        "id": "3dT4kFn7Kjip"
      },
      "id": "3dT4kFn7Kjip",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test_doente2, y_pred_doente)"
      ],
      "metadata": {
        "id": "CObRn1nwKpym"
      },
      "id": "CObRn1nwKpym",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(11,7))\n",
        "x_axis_labels = classes_doente\n",
        "y_axis_labels = classes_doente\n",
        "plt.rcParams.update({'font.size': 25})\n",
        "sns.heatmap(cm, xticklabels = x_axis_labels, yticklabels = y_axis_labels, annot= True, fmt='',cmap = 'Blues')\n",
        "plt.xlabel('Predição', fontsize = 20)\n",
        "plt.ylabel(\"Real\", fontsize = 20)\n",
        "plt.title('Matriz de confusão ')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iAzE6PBzKlqr"
      },
      "id": "iAzE6PBzKlqr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_input = keras.applications.mobilenet_v2.preprocess_input\n",
        "decode_predictions = keras.applications.mobilenet_v2.decode_predictions\n",
        "\n",
        "last_conv_layer_name = 'conv2d_93'\n",
        "\n",
        "# Remove-se o softmax da última camada\n",
        "model.layers[-1].activation = None"
      ],
      "metadata": {
        "id": "5ic9yhmioFha"
      },
      "id": "5ic9yhmioFha",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibe a parte das imagens usadas pela rede neural para classificar as imagens\n",
        "fig, axes = plt.subplots(nrows = 4, ncols = 4, figsize = (20, 20), subplot_kw = {'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    img_array = X_test_doente[i]\n",
        "    heatmap = make_gradcam_heatmap(img_array.reshape(1, 256, 256, 3), model, last_conv_layer_name)\n",
        "    cam_path = save_and_display_gradcam(img_array, heatmap, \"cam.jpg\", 0.8)\n",
        "    class_test = classes[y_test_doente2[i]]\n",
        "    class_prediction = classes[y_pred_doente[i]]\n",
        "    ax.imshow(plt.imread(cam_path))\n",
        "    ax.set_title(f\"True: {class_test}\\nPredicted: {class_prediction}\", fontsize = 14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0UKqw7uvoEic"
      },
      "id": "0UKqw7uvoEic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMh_f7y5ZgjJ"
      },
      "source": [
        "## **Cross Validation (Validação Cruzada)**\n",
        "\n",
        "O objetivo da validação cruzada é o particionamento do conjunto de dados em subconjuntos exclusivos, para posteriormente utilizar alguns dos subconjuntos, dados de treinamento, para a estimação dos parâmetros do modelo, sendo os subconjuntos restantes, dados de validação e/ou de teste, empregados na validação do modelo."
      ],
      "id": "CMh_f7y5ZgjJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v_nvMwVWZfcN"
      },
      "outputs": [],
      "source": [
        "def cross_validation(model, x_res, epochs, batch_size, cv, mask):\n",
        "  model = model_classifier(model)\n",
        "\n",
        "  early_stopping = keras.callbacks.EarlyStopping(monitor='loss', patience = 3)\n",
        "  reduce_lr =  keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
        "  learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=2, factor=0.5, min_lr=0.00001)\n",
        "  checkpoint_path = 'training_1/model.ckpt'\n",
        "  checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "  model_check = keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, monitor = 'val_accuracy', mode = 'max', save_best_only=True, verbose=1)\n",
        "  cp_callback = [early_stopping, reduce_lr , learning_rate_reduction, model_check]\n",
        "\n",
        "  accuracy = []\n",
        "  precision = []\n",
        "  recall = []\n",
        "  f1 = []\n",
        "  for i in range(cv):\n",
        "    X_train, X_val, X_test, X_train_mask, X_val_mask, X_test_mask, y_train, y_val, y_test = divide_base_date(x_res,0)\n",
        "\n",
        "    # Etiquetas de codificação\n",
        "    encoder = LabelEncoder()\n",
        "    y_train = encoder.fit_transform(y_train)\n",
        "    y_val = encoder.fit_transform(y_val)\n",
        "    y_test = encoder.fit_transform(y_test)\n",
        "\n",
        "    if mask:\n",
        "      X_train = np.array(X_train_mask)\n",
        "      X_val = np.array(X_val_mask)\n",
        "      X_test = np.array(X_test_mask)\n",
        "    else:\n",
        "      X_train = np.array(X_train)\n",
        "      X_val = np.array(X_val)\n",
        "      X_test = np.array(X_test)\n",
        "\n",
        "    classes = list(encoder.classes_)\n",
        "\n",
        "    print(f\"Iteração {i+1}/{cv}\")\n",
        "    model_history = model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size, validation_data = (X_val, y_val), callbacks = cp_callback)\n",
        "\n",
        "    prob_pred = model.predict(X_test)\n",
        "    y_pred = np.argmax(prob_pred, axis = 1)\n",
        "\n",
        "    accuracy.append(accuracy_score(y_test, y_pred))\n",
        "    precision.append(precision_score(y_test, y_pred, average = 'weighted', zero_division = 1))\n",
        "    recall.append(recall_score(y_test, y_pred, average = 'weighted', zero_division = 1))\n",
        "    f1.append(f1_score(y_test, y_pred, average = 'weighted', zero_division = 1))\n",
        "\n",
        "  # Métricas para avaliação do modelo\n",
        "  test_accuracy = accuracy\n",
        "  test_accuracy_mean = np.average(accuracy)*100\n",
        "  test_precision = precision\n",
        "  test_precision_mean = np.average(precision)\n",
        "  test_recall = recall\n",
        "  test_recall_mean = np.average(recall)\n",
        "  test_f1 = f1\n",
        "  test_f1_mean = np.average(f1)\n",
        "\n",
        "  metrics = {\"Validation Accuracy scores\": test_accuracy,\"Mean Validation Accuracy\": test_accuracy_mean, \"Validation Precision scores\": test_precision,\n",
        "          \"Mean Validation Precision\": test_precision_mean, \"Validation Recall scores\": test_recall, \"Mean Validation Recall\": test_recall_mean,\n",
        "          \"Validation F1 scores\": test_f1, \"Mean Validation F1 Score\": test_f1_mean}\n",
        "\n",
        "  return metrics"
      ],
      "id": "v_nvMwVWZfcN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwEt2ehejedg"
      },
      "outputs": [],
      "source": [
        "cross_validation(\"vgg16\", images, 30, 25, 5, True)"
      ],
      "id": "HwEt2ehejedg"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 2358.198739,
      "end_time": "2022-08-09T11:45:56.043933",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-08-09T11:06:37.845194",
      "version": "2.3.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}